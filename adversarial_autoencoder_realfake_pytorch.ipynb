{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcQzCvwIUwNW1r5v4Qf5kF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yastiaisyah/DataSynthesis/blob/main/adversarial_autoencoder_realfake_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Autentikasi di Google Colab\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Definisikan transformasi yang ingin Anda terapkan pada gambar\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Buat custom dataset\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, drive, folder_id, transform=None):\n",
        "        self.drive = drive\n",
        "        self.folder_id = folder_id\n",
        "        self.file_list = self.get_file_list()\n",
        "        self.transform = transform\n",
        "\n",
        "    def get_file_list(self):\n",
        "        file_list = self.drive.ListFile({'q': \"'{}' in parents\".format(self.folder_id)}).GetList()\n",
        "        return file_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file = self.file_list[idx]\n",
        "        img = self.load_image(file)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "    @staticmethod\n",
        "    def load_image(file):\n",
        "        img = drive.CreateFile({'id': file['id']})\n",
        "        img.GetContentFile(file['title'])\n",
        "        img = Image.open(file['title'])\n",
        "        return img\n",
        "\n",
        "# Ganti 'YOUR_FOLDER_ID' dengan ID folder Google Drive yang sesuai\n",
        "folder_id = '1gkvKPLPtyTlUUdLVZ0yOiL0Vga-enW6n'\n",
        "\n",
        "# Gunakan custom dataset untuk mengakses gambar-gambar\n",
        "google_drive_dataset = CustomImageDataset(drive, folder_id, transform=transform)\n",
        "\n",
        "# Tentukan ukuran batch (mb_size) sesuai dengan preferensi Anda\n",
        "mb_size = 32  # Misalnya, gunakan ukuran batch 32\n",
        "z_dim = 5\n",
        "h_dim = 128\n",
        "X_dim = 28 * 28  # Untuk gambar berukuran 28x28 piksel\n",
        "lr = 1e-3\n",
        "\n",
        "# DataLoader untuk dataset\n",
        "data_loader = DataLoader(google_drive_dataset, batch_size=mb_size, shuffle=True)\n",
        "\n",
        "# Lanjutkan dengan definisi model dan pelatihan sesuai yang telah Anda lakukan sebelumnya.\n",
        "\n",
        "# Encoder\n",
        "Q = nn.Sequential(\n",
        "    nn.Linear(X_dim, h_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(h_dim, z_dim)\n",
        ")\n",
        "\n",
        "# Decoder\n",
        "P = nn.Sequential(\n",
        "    nn.Linear(z_dim, h_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(h_dim, X_dim),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Discriminator\n",
        "D = nn.Sequential(\n",
        "    nn.Linear(z_dim, h_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(h_dim, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "def reset_grad():\n",
        "    Q.zero_grad()\n",
        "    P.zero_grad()\n",
        "    D.zero_grad()\n",
        "\n",
        "Q_solver = optim.Adam(Q.parameters(), lr=lr)\n",
        "P_solver = optim.Adam(P.parameters(), lr=lr)\n",
        "D_solver = optim.Adam(D.parameters(), lr=lr)\n",
        "\n",
        "cnt = 0\n",
        "\n",
        "for it in range(100000):\n",
        "    for X in data_loader:\n",
        "        \"\"\" Reconstruction phase \"\"\"\n",
        "        z_sample = Q(X.view(mb_size, 1, 28, 28))\n",
        "        X_sample = P(z_sample)\n",
        "\n",
        "        # Clip values to be within [0, 1]\n",
        "        X_sample = X_sample.clamp(0, 1)\n",
        "\n",
        "        # Use BCELoss for binary cross entropy\n",
        "        recon_loss = nn.BCELoss()(X_sample, X.view(-1, X_dim))\n",
        "\n",
        "        recon_loss.backward()\n",
        "        P_solver.step()\n",
        "        Q_solver.step()\n",
        "        reset_grad()\n",
        "\n",
        "        \"\"\" Regularization phase \"\"\"\n",
        "        # Discriminator\n",
        "        z_real = torch.randn(mb_size, z_dim)\n",
        "        z_fake = Q(X.view(-1, X_dim))\n",
        "\n",
        "        D_real = D(z_real)\n",
        "        D_fake = D(z_fake)\n",
        "\n",
        "        D_loss = -torch.mean(torch.log(D_real) + torch.log(1 - D_fake))\n",
        "\n",
        "        D_loss.backward()\n",
        "        D_solver.step()\n",
        "        reset_grad()\n",
        "\n",
        "        # Generator\n",
        "        z_fake = Q(X.view(-1, X_dim))\n",
        "        D_fake = D(z_fake)\n",
        "\n",
        "        G_loss = -torch.mean(torch.log(D_fake))\n",
        "\n",
        "        G_loss.backward()\n",
        "        Q_solver.step()\n",
        "        reset_grad()\n",
        "\n",
        "        # Print and plot every now and then\n",
        "        if it % 1000 == 0:\n",
        "            print('Iter-{}; D_loss: {:.4}; G_loss: {:.4}; recon_loss: {:.4}'\n",
        "                  .format(it, D_loss.item(), G_loss.item(), recon_loss.item()))\n",
        "\n",
        "            samples = P(z_real).data.numpy()[:16]\n",
        "\n",
        "            fig = plt.figure(figsize=(4, 4))\n",
        "            gs = gridspec.GridSpec(4, 4)\n",
        "            gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "            for i, sample in enumerate(samples):\n",
        "                ax = plt.subplot(gs[i])\n",
        "                plt.axis('off')\n",
        "                ax.set_xticklabels([])\n",
        "                ax.set_yticklabels([])\n",
        "                ax.set_aspect('equal')\n",
        "                plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
        "\n",
        "            if not os.path.exists('out/'):\n",
        "                os.makedirs('out/')\n",
        "\n",
        "            plt.savefig('out/{}.png'\n",
        "                        .format(str(cnt).zfill(3)), bbox_inches='tight')\n",
        "            cnt += 1\n",
        "            plt.close(fig)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "yd82Lcwu09l5",
        "outputId": "8ad093d6-80d5-4fca-d7b9-113d72aeacd6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-30aaf6b35ca5>\u001b[0m in \u001b[0;36m<cell line: 112>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;34m\"\"\" Reconstruction phase \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mz_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mX_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[32, 1, 28, 28]' is invalid for input of size 34560000"
          ]
        }
      ]
    }
  ]
}