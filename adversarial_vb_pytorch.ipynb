{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yastiaisyah/DataSynthesis/blob/main/adversarial_vb_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH_kYYmPM8rm",
        "outputId": "efd31748-731e-4258-f6c9-c6a600ab0e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter-0; ELBO: -0.7672; T_loss: -1.392\n",
            "Iter-1000; ELBO: -0.57; T_loss: -1.202\n",
            "Iter-2000; ELBO: -0.5589; T_loss: -1.284\n",
            "Iter-3000; ELBO: -0.177; T_loss: -1.535\n",
            "Iter-4000; ELBO: -0.05884; T_loss: -1.843\n",
            "Iter-5000; ELBO: 0.04947; T_loss: -1.809\n",
            "Iter-6000; ELBO: -0.9025; T_loss: -0.8915\n",
            "Iter-7000; ELBO: -0.1426; T_loss: -1.527\n",
            "Iter-8000; ELBO: -0.3228; T_loss: -1.497\n",
            "Iter-9000; ELBO: -0.1759; T_loss: -1.428\n",
            "Iter-10000; ELBO: -0.3033; T_loss: -1.331\n",
            "Iter-11000; ELBO: -0.8133; T_loss: -0.9189\n",
            "Iter-12000; ELBO: -0.08549; T_loss: -1.662\n",
            "Iter-13000; ELBO: -0.1683; T_loss: -1.495\n",
            "Iter-14000; ELBO: -0.2285; T_loss: -1.326\n",
            "Iter-15000; ELBO: -1.148; T_loss: -0.8903\n",
            "Iter-16000; ELBO: -0.479; T_loss: -1.323\n",
            "Iter-17000; ELBO: -0.3013; T_loss: -1.39\n",
            "Iter-18000; ELBO: -0.3194; T_loss: -1.341\n",
            "Iter-19000; ELBO: -0.5852; T_loss: -1.186\n",
            "Iter-20000; ELBO: -0.1892; T_loss: -1.495\n",
            "Iter-21000; ELBO: -0.3854; T_loss: -1.348\n",
            "Iter-22000; ELBO: -0.4924; T_loss: -1.319\n",
            "Iter-23000; ELBO: -0.2182; T_loss: -1.344\n",
            "Iter-24000; ELBO: -0.1939; T_loss: -1.421\n",
            "Iter-25000; ELBO: -0.3388; T_loss: -1.136\n",
            "Iter-26000; ELBO: -0.4457; T_loss: -1.261\n",
            "Iter-27000; ELBO: -0.742; T_loss: -1.248\n",
            "Iter-28000; ELBO: -0.3513; T_loss: -1.538\n",
            "Iter-29000; ELBO: -0.5311; T_loss: -1.194\n",
            "Iter-30000; ELBO: -0.4815; T_loss: -1.216\n",
            "Iter-31000; ELBO: -0.2697; T_loss: -1.169\n",
            "Iter-32000; ELBO: -0.6164; T_loss: -1.263\n",
            "Iter-33000; ELBO: -0.3511; T_loss: -1.328\n",
            "Iter-34000; ELBO: -0.2825; T_loss: -1.318\n",
            "Iter-35000; ELBO: -1.474; T_loss: -0.7904\n",
            "Iter-36000; ELBO: -1.545; T_loss: -1.326\n",
            "Iter-37000; ELBO: -0.9067; T_loss: -1.165\n",
            "Iter-38000; ELBO: 0.05778; T_loss: -1.772\n",
            "Iter-39000; ELBO: -0.5941; T_loss: -1.453\n",
            "Iter-40000; ELBO: -0.7314; T_loss: -1.105\n",
            "Iter-41000; ELBO: -0.4395; T_loss: -1.132\n",
            "Iter-42000; ELBO: -0.6381; T_loss: -1.163\n",
            "Iter-43000; ELBO: -0.1796; T_loss: -1.538\n",
            "Iter-44000; ELBO: -0.9362; T_loss: -1.112\n",
            "Iter-45000; ELBO: -0.8458; T_loss: -1.001\n",
            "Iter-46000; ELBO: -0.2197; T_loss: -1.406\n",
            "Iter-47000; ELBO: -0.3391; T_loss: -1.439\n",
            "Iter-48000; ELBO: -0.6174; T_loss: -1.171\n",
            "Iter-49000; ELBO: -0.4615; T_loss: -1.682\n",
            "Iter-50000; ELBO: -0.494; T_loss: -1.617\n",
            "Iter-51000; ELBO: -0.2008; T_loss: -1.37\n",
            "Iter-52000; ELBO: -0.3065; T_loss: -1.336\n",
            "Iter-53000; ELBO: -0.4833; T_loss: -1.348\n",
            "Iter-54000; ELBO: -0.1749; T_loss: -1.488\n",
            "Iter-55000; ELBO: -0.401; T_loss: -1.243\n",
            "Iter-56000; ELBO: -1.195; T_loss: -1.084\n",
            "Iter-57000; ELBO: -0.4558; T_loss: -1.217\n",
            "Iter-58000; ELBO: -0.5321; T_loss: -1.3\n",
            "Iter-59000; ELBO: -0.2957; T_loss: -1.399\n",
            "Iter-60000; ELBO: -0.5112; T_loss: -1.504\n",
            "Iter-61000; ELBO: -0.1577; T_loss: -1.565\n",
            "Iter-62000; ELBO: -0.3442; T_loss: -1.35\n",
            "Iter-63000; ELBO: -0.5367; T_loss: -1.26\n",
            "Iter-64000; ELBO: -0.4669; T_loss: -1.231\n",
            "Iter-65000; ELBO: -0.4747; T_loss: -1.417\n",
            "Iter-66000; ELBO: -0.4023; T_loss: -1.522\n",
            "Iter-67000; ELBO: -0.3473; T_loss: -1.335\n",
            "Iter-68000; ELBO: -0.3584; T_loss: -1.32\n",
            "Iter-69000; ELBO: -0.1666; T_loss: -1.496\n",
            "Iter-70000; ELBO: -0.3728; T_loss: -1.378\n",
            "Iter-71000; ELBO: -0.1475; T_loss: -1.717\n",
            "Iter-72000; ELBO: -0.3919; T_loss: -1.482\n",
            "Iter-73000; ELBO: -0.3866; T_loss: -1.278\n",
            "Iter-74000; ELBO: -0.4288; T_loss: -1.372\n",
            "Iter-75000; ELBO: -0.4813; T_loss: -1.33\n",
            "Iter-76000; ELBO: -0.4786; T_loss: -1.239\n",
            "Iter-77000; ELBO: -0.5471; T_loss: -1.618\n",
            "Iter-78000; ELBO: -0.2028; T_loss: -1.418\n",
            "Iter-79000; ELBO: -0.1001; T_loss: -1.453\n",
            "Iter-80000; ELBO: -0.2317; T_loss: -1.34\n",
            "Iter-81000; ELBO: -0.2974; T_loss: -1.277\n",
            "Iter-82000; ELBO: -0.1742; T_loss: -1.449\n",
            "Iter-83000; ELBO: -0.2851; T_loss: -1.427\n",
            "Iter-84000; ELBO: -0.6482; T_loss: -1.319\n",
            "Iter-85000; ELBO: -0.2577; T_loss: -1.427\n",
            "Iter-86000; ELBO: -0.2693; T_loss: -1.386\n",
            "Iter-87000; ELBO: -0.2237; T_loss: -1.386\n",
            "Iter-88000; ELBO: -0.1952; T_loss: -1.385\n",
            "Iter-89000; ELBO: -0.2221; T_loss: -1.403\n",
            "Iter-90000; ELBO: -0.2059; T_loss: -1.389\n",
            "Iter-91000; ELBO: -0.2103; T_loss: -1.387\n",
            "Iter-92000; ELBO: -0.246; T_loss: -1.39\n",
            "Iter-93000; ELBO: -0.2144; T_loss: -1.388\n",
            "Iter-94000; ELBO: -0.1806; T_loss: -1.384\n",
            "Iter-95000; ELBO: -0.2202; T_loss: -1.342\n",
            "Iter-96000; ELBO: -0.1821; T_loss: -1.388\n",
            "Iter-97000; ELBO: -0.1688; T_loss: -1.389\n",
            "Iter-98000; ELBO: -0.3307; T_loss: -1.371\n",
            "Iter-99000; ELBO: -0.1912; T_loss: -1.391\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "from torch.autograd import Variable\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "# Normalize the data to [0, 1] range\n",
        "mnist.data = mnist.data.float() / 255.0\n",
        "\n",
        "# Parameters\n",
        "mb_size = 32\n",
        "z_dim = 5\n",
        "X_dim = mnist.data.size(1) * mnist.data.size(2)  # Flattened image dimensions\n",
        "h_dim = 128\n",
        "lr = 1e-3\n",
        "\n",
        "# Create noise dimension\n",
        "eps_dim = 10  # Dimension of the noise vector\n",
        "\n",
        "# Encoder: q(z|x,eps)\n",
        "Q = torch.nn.Sequential(\n",
        "    torch.nn.Linear(X_dim + eps_dim, h_dim),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(h_dim, z_dim)\n",
        ")\n",
        "\n",
        "# Decoder: p(x|z)\n",
        "P = torch.nn.Sequential(\n",
        "    torch.nn.Linear(z_dim, h_dim),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(h_dim, X_dim),\n",
        "    torch.nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Discriminator: T(X, z)\n",
        "T = torch.nn.Sequential(\n",
        "    torch.nn.Linear(X_dim + z_dim, h_dim),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(h_dim, 1)\n",
        ")\n",
        "\n",
        "def reset_grad():\n",
        "    Q.zero_grad()\n",
        "    P.zero_grad()\n",
        "    T.zero_grad()\n",
        "\n",
        "\n",
        "def sample_X(size):\n",
        "    indices = np.random.randint(0, len(mnist), size)\n",
        "    X = mnist.data[indices].view(size, -1).float()\n",
        "    return Variable(X)\n",
        "\n",
        "\n",
        "# Optimizers\n",
        "Q_solver = optim.Adam(Q.parameters(), lr=lr)\n",
        "P_solver = optim.Adam(P.parameters(), lr=lr)\n",
        "T_solver = optim.Adam(T.parameters(), lr=lr)\n",
        "\n",
        "# Initialize counter\n",
        "cnt = 0\n",
        "\"\"\"1000000\"\"\"\n",
        "\n",
        "# Your training loop goes here\n",
        "for it in range(100000):\n",
        "    X = sample_X(mb_size)\n",
        "    eps = Variable(torch.randn(mb_size, eps_dim))\n",
        "    z = Variable(torch.randn(mb_size, z_dim))\n",
        "\n",
        "    # Optimize VAE\n",
        "    z_sample = Q(torch.cat([X, eps], 1))\n",
        "    X_sample = P(z_sample)\n",
        "    T_sample = T(torch.cat([X, z_sample], 1))\n",
        "\n",
        "    disc = torch.mean(-T_sample)\n",
        "    loglike = -nn.BCELoss()(X_sample, X) # Use BCELoss for binary cross-entropy\n",
        "\n",
        "    elbo = -(disc + loglike)\n",
        "\n",
        "    elbo.backward()\n",
        "    Q_solver.step()\n",
        "    P_solver.step()\n",
        "    reset_grad()\n",
        "\n",
        "    # Discriminator T(X, z)\n",
        "    z_sample = Q(torch.cat([X, eps], 1))\n",
        "    T_q = nn.Sigmoid()(T(torch.cat([X, z_sample], 1)))\n",
        "    T_prior = nn.Sigmoid()(T(torch.cat([X, z], 1)))\n",
        "\n",
        "    T_loss = -torch.mean(torch.log(T_q) + torch.log(1. - T_prior))\n",
        "\n",
        "    T_loss.backward()\n",
        "    T_solver.step()\n",
        "    reset_grad()\n",
        "\n",
        "    # Print and plot every now and then\n",
        "    if it % 1000 == 0:\n",
        "        print('Iter-{}; ELBO: {:.4}; T_loss: {:.4}'\n",
        "              .format(it, -elbo.item(), -T_loss.item()))\n",
        "\n",
        "        samples = P(z).data.numpy()[:16]\n",
        "\n",
        "        fig = plt.figure(figsize=(4, 4))\n",
        "        gs = gridspec.GridSpec(4, 4)\n",
        "        gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "        for i, sample in enumerate(samples):\n",
        "            ax = plt.subplot(gs[i])\n",
        "            plt.axis('off')\n",
        "            ax.set_xticklabels([])\n",
        "            ax.set_yticklabels([])\n",
        "            ax.set_aspect('equal')\n",
        "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
        "\n",
        "        if not os.path.exists('out/'):\n",
        "            os.makedirs('out/')\n",
        "\n",
        "        plt.savefig('out/{}.png'\n",
        "                    .format(str(cnt).zfill(3)), bbox_inches='tight')\n",
        "        cnt += 1\n",
        "        plt.close(fig)"
      ]
    }
  ]
}